{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79866959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from dataset import KeypointRandDataset, KeypointRotDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa74b7a",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004c90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataset\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(dataset)\n",
    "\n",
    "train_json = \"train/_mediapipe_annotated.json\"\n",
    "val_json = \"valid/_mediapipe_annotated.json\"\n",
    "test_json = \"test/_mediapipe_annotated.json\"\n",
    "input_dim = 63  # 21 keypoints * 3 coordinates\n",
    "hidden_dim = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063226d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 26  # Adjust based on your dataset\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = KeypointRotDataset(train_json,  True)\n",
    "val_dataset = KeypointRotDataset(val_json, True)\n",
    "test_dataset = KeypointRotDataset(test_json, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27759639",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.read_csv(\"mp_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b78c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keypoints_new = new_dataset.values[:, 2:].reshape(-1, 21, 3).astype(np.float32)\n",
    "train_labels_new = new_dataset.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db888c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([train_dataset.keypoints, train_keypoints_new]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46db680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66508,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([train_dataset.categories, train_labels_new]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93028a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66508, 42) (66508,) (61, 42) (61,) (133, 42) (133,)\n"
     ]
    }
   ],
   "source": [
    "train_keypoints = np.concatenate([train_dataset.keypoints, train_keypoints_new])\n",
    "X_train = train_keypoints - train_keypoints[:, [9]]\n",
    "palm_length = np.linalg.norm(X_train[:, 9, :2] - X_train[:, 0, :2], axis=1, keepdims=True)\n",
    "X_train = X_train[:, :, :2].reshape(-1, 42) / palm_length\n",
    "# print(X_train)\n",
    "# X_train = X_train[:, :, :3].reshape(-1, 63)\n",
    "y_train = np.concatenate([train_dataset.categories, train_labels_new])\n",
    "\n",
    "val_keypoints = val_dataset.keypoints\n",
    "X_val = val_keypoints - val_keypoints[:, [9]]\n",
    "palm_length = np.linalg.norm(X_val[:, 9, :2] - X_val[:, 0, :2], axis=1, keepdims=True)\n",
    "X_val = X_val[:, :, :2].reshape(-1, 42) / palm_length\n",
    "# X_val = X_val[:, :, :3].reshape(-1, 63)\n",
    "y_val = val_dataset.categories\n",
    "\n",
    "test_keypoints = test_dataset.keypoints\n",
    "X_test = test_keypoints - test_keypoints[:, [9]]\n",
    "palm_length = np.linalg.norm(X_test[:, 9, :2] - X_test[:, 0, :2], axis=1, keepdims=True)\n",
    "X_test = X_test[:, :, :2].reshape(-1, 42) / palm_length\n",
    "# X_test = X_test[:, :, :3].reshape(-1, 63)\n",
    "y_test = test_dataset.categories\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e548d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.update_data(X_train, y_train)\n",
    "val_dataset.update_data(X_val, y_val)\n",
    "test_dataset.update_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecce183",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "80267dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=1),  # Output: 16 x 5 x 5\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),  # Output: 32 x 5 x 5\n",
    "            # nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4 * 5 * 5, hidden_dim),  # Flattened input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Flattened input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Flattened input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # Flattened input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870686b8",
   "metadata": {},
   "source": [
    "## Train Val Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67ae720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_precisions = []\n",
    "    val_recalls = []\n",
    "    val_f1s = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for keypoints, labels in train_loader:\n",
    "            keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(keypoints)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Evaluate on the validation set at the end of each epoch\n",
    "        val_loss, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model_with_metrics(model, val_loader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "\n",
    "        # print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        # print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "        # print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies, val_precisions, val_recalls, val_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a530b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def evaluate_model_with_metrics(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for keypoints, labels in dataloader:\n",
    "            keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "            outputs = model(keypoints)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            # predicted[_<0.5] = 0\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01bde351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(train_losses, val_losses, val_accuracies, val_precisions, val_recalls, val_f1, epochs = 40):\n",
    "    epochs = list(range(1, epochs+1))\n",
    "    metrics = {\n",
    "        \"Train Loss\": train_losses,\n",
    "        \"Validation Loss\": val_losses,\n",
    "        \"Validation Accuracy\": val_accuracies,\n",
    "        \"Validation Precision\": val_precisions,\n",
    "        \"Validation Recall\": val_recalls,\n",
    "        \"Validation F1 Score\": val_f1\n",
    "    }\n",
    "\n",
    "    # Create subplots\n",
    "    num_metrics = len(metrics)\n",
    "    fig, axes = plt.subplots(num_metrics, 1, figsize=(10, 18), sharex=True)\n",
    "\n",
    "    for i, (label, values) in enumerate(metrics.items()):\n",
    "        axes[i].plot(epochs, values, label=label, marker='o')\n",
    "        axes[i].set_title(label)\n",
    "        axes[i].set_ylabel(label)\n",
    "        axes[i].grid(True)\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Set common X label\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34a4a1",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d73515d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 26  # Adjust based on your dataset\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 0.0005\n",
    "epochs = 100\n",
    "hidden_dim = 256\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset.set_rand_rot(False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb12668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n",
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay = weight_decay)\n",
    "\n",
    "# Train and Evaluate\n",
    "train_losses, val_losses, val_accuracies, val_precisions, val_recalls, val_f1 = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs)\n",
    "\n",
    "plot(train_losses, val_losses, val_accuracies, val_precisions, val_recalls, val_f1, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdcb886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyicheng/Desktop/24Fall/11767/ASL/dataset.py:287: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(keypoint, dtype=torch.float32), torch.tensor(category, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.04587784409523,\n",
       " 0.6691729323308271,\n",
       " 0.7028830192364026,\n",
       " 0.6691729323308271,\n",
       " 0.655442406382256)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_with_metrics(model, val_loader, criterion, torch.device(\"mps\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a58a743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_new_dataset_76.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python python3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
