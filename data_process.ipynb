{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732399012.025690 11584490 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 76.3), renderer: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732399012.051788 11658436 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1732399012.063388 11658436 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train'\n",
    "train = json.load(open('train/_annotations.coco.json', 'r'))\n",
    "valid = json.load(open('valid/_annotations.coco.json', 'r'))\n",
    "test = json.load(open('test/_annotations.coco.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'licenses', 'categories', 'images', 'annotations'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732399077.301644 11584490 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 76.3), renderer: Apple M2\n",
      "W0000 00:00:1732399077.328995 11661022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1732399077.338120 11661022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Assuming 'valid' is a dictionary with 'images' and 'annotations'\n",
    "# valid = {'images': [{'file_name': 'example.jpg'}], 'annotations': [{}]}\n",
    "\n",
    "with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "    for img, anno in zip(train['images'], train['annotations']):\n",
    "        # Read the image\n",
    "        img_src = img['file_name']\n",
    "        image_path = os.path.join(\"train\", img_src)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"Error reading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        # Convert to RGB for Mediapipe\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image and detect hands\n",
    "        results = hands.process(image_rgb)\n",
    "\n",
    "        # Extract hand keypoints\n",
    "        keypoints = []\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                if len(hand_landmarks.landmark):\n",
    "                    keypoints.extend()\n",
    "                keypoints.extend([[h.x, h.y, h.z] for h in hand_landmarks.landmark])\n",
    "                \n",
    "\n",
    "        # Update the annotations with detected keypoints\n",
    "        anno['keypoints'] = keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train/_mediapipe_annotated.json\", 'w') as json_file:\n",
    "    json.dump(train, json_file, indent=4)\n",
    "    json_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'image_id': 0, 'category_id': 21, 'bbox': [38, 69, 309, 320], 'area': 98880, 'segmentation': [], 'iscrowd': 0, 'keypoints': [[0.36088794469833374, 0.9621922969818115, 2.2833357888885075e-06], [0.2959299385547638, 0.9361520409584045, -0.24523542821407318], [0.33899691700935364, 0.8656842112541199, -0.37749361991882324], [0.48457369208335876, 0.8498654961585999, -0.47721728682518005], [0.6270965337753296, 0.8204878568649292, -0.5697835683822632], [0.3679077923297882, 0.6277342438697815, -0.2914912700653076], [0.4215954840183258, 0.4702984094619751, -0.4178166389465332], [0.4583439230918884, 0.35678133368492126, -0.5003247261047363], [0.503635585308075, 0.26581311225891113, -0.5583831071853638], [0.502713143825531, 0.6477923393249512, -0.24109266698360443], [0.545171856880188, 0.4625917673110962, -0.37003904581069946], [0.5801420211791992, 0.35572129487991333, -0.4501192271709442], [0.6257253885269165, 0.23469625413417816, -0.5035102963447571], [0.6110242605209351, 0.7115523815155029, -0.21025316417217255], [0.7095853090286255, 0.6217364072799683, -0.3729696571826935], [0.6560802459716797, 0.7466244101524353, -0.4230446517467499], [0.5994464159011841, 0.8190262913703918, -0.4296671450138092], [0.7015306949615479, 0.793079137802124, -0.1970486342906952], [0.7921078205108643, 0.7628180384635925, -0.33671244978904724], [0.7381982207298279, 0.8296412229537964, -0.38124847412109375], [0.6623239517211914, 0.8706275820732117, -0.39589476585388184]]}\n",
      "{'id': 1, 'image_id': 1, 'category_id': 16, 'bbox': [84, 203, 245.9326825528001, 128.82756099298763], 'area': 31682.90766173992, 'segmentation': [], 'iscrowd': 0, 'keypoints': [[0.23134684562683105, 0.8248361349105835, 1.510827019046701e-06], [0.36385536193847656, 0.7741440534591675, -0.010780712589621544], [0.5074301958084106, 0.7402724027633667, -0.028773359954357147], [0.6340737342834473, 0.7616440057754517, -0.055599749088287354], [0.7269482612609863, 0.78996741771698, -0.08578143268823624], [0.5144661664962769, 0.5975774526596069, -0.02670442685484886], [0.6908158659934998, 0.569364607334137, -0.06661445647478104], [0.8007917404174805, 0.5660006999969482, -0.09302721172571182], [0.8857681751251221, 0.5695235133171082, -0.10819762945175171], [0.4994003474712372, 0.6111918687820435, -0.04432867094874382], [0.687673807144165, 0.6049384474754333, -0.07536885887384415], [0.7989025115966797, 0.6082594394683838, -0.10105486959218979], [0.8836806416511536, 0.6149968504905701, -0.1211714968085289], [0.47698262333869934, 0.6500484943389893, -0.06412292271852493], [0.6568182706832886, 0.7216954231262207, -0.10927994549274445], [0.7285920977592468, 0.7746956944465637, -0.13602830469608307], [0.7773443460464478, 0.8129091262817383, -0.14645139873027802], [0.4513653814792633, 0.7082682847976685, -0.08389288187026978], [0.5925653576850891, 0.7765117883682251, -0.11686097085475922], [0.6671831011772156, 0.8173481225967407, -0.12797017395496368], [0.7226387858390808, 0.8544421792030334, -0.12995365262031555]]}\n"
     ]
    }
   ],
   "source": [
    "print(train['annotations'][0])\n",
    "print(train['annotations'][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python python3",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
